# streamlit_app.py
import streamlit as st
import pandas as pd
import altair as alt
from pathlib import Path

st.set_page_config(page_title="MBTI Top10 by Country", layout="wide")

MBTI_16 = [
    "INTJ","INTP","ENTJ","ENTP","INFJ","INFP","ENFJ","ENFP",
    "ISTJ","ISFJ","ESTJ","ESFJ","ISTP","ISFP","ESTP","ESFP"
]

DEFAULT_FILE = "countriesMBTI_16types.csv"  # ê°™ì€ í´ë” íŒŒì¼ ìš°ì„ 

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì •ê·œí™”: wide(16ìœ í˜• ì—´) â†’ long(country, type, percentage)
# long ì…ë ¥ë„ ìë™ ì¸ì‹( country / type / value(percentage) )
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _is_wide(df: pd.DataFrame) -> bool:
    cols = [c.strip().upper() for c in df.columns]
    return sum(c in MBTI_16 for c in cols) >= 10

def _detect_country_col(df: pd.DataFrame):
    for c in df.columns:
        lc = str(c).strip().lower()
        if lc in ["country", "nation", "ì§€ì—­", "êµ­ê°€", "êµ­ê°€ëª…", "ë‚˜ë¼"]:
            return c
    return df.columns[0]

def _to_long_from_wide(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [c.strip() for c in df.columns]
    country_col = _detect_country_col(df)
    mbti_cols = [c for c in df.columns if c.upper() in MBTI_16]
    melted = df.melt(id_vars=[country_col], value_vars=mbti_cols,
                     var_name="type", value_name="value").rename(columns={country_col:"country"})
    melted["type"] = melted["type"].str.upper().str.strip()
    if pd.api.types.is_numeric_dtype(melted["value"]):
        vals = melted["value"].dropna()
        if len(vals) and vals.max() <= 1.0:
            melted["value"] = melted["value"] * 100.0
    melted["percentage"] = melted["value"]
    out = melted[["country","type","percentage"]].copy()
    out["percentage"] = pd.to_numeric(out["percentage"], errors="coerce")
    out = out[(out["percentage"]>=0) & (out["percentage"]<=100)]
    return out[out["type"].isin(MBTI_16)]

def _to_long_from_longish(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    cols_lower = {c.lower(): c for c in df.columns}
    country_col = cols_lower.get("country", _detect_country_col(df))
    type_col    = cols_lower.get("type", None)

    value_col = None
    for k in ["percentage","value","ratio","share","percent"]:
        if k in cols_lower:
            value_col = cols_lower[k]; break
    if value_col is None:
        num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
        value_col = num_cols[0] if num_cols else None

    out = df[[country_col, type_col, value_col]].rename(
        columns={country_col:"country", type_col:"type", value_col:"percentage"}
    )
    out["type"] = out["type"].astype(str).str.upper().str.strip()
    if pd.api.types.is_numeric_dtype(out["percentage"]):
        vals = out["percentage"].dropna()
        if len(vals) and vals.max() <= 1.0:
            out["percentage"] = out["percentage"] * 100.0
    out["percentage"] = pd.to_numeric(out["percentage"], errors="coerce")
    out = out[(out["percentage"]>=0) & (out["percentage"]<=100)]
    return out[out["type"].isin(MBTI_16)].dropna(subset=["country","type","percentage"])

def normalize_to_long(df: pd.DataFrame) -> pd.DataFrame:
    return _to_long_from_wide(df) if _is_wide(df) else _to_long_from_longish(df)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° ë¡œë“œ: ê°™ì€ í´ë” íŒŒì¼ ìš°ì„  â†’ ì—†ìœ¼ë©´ ì—…ë¡œë” ì‚¬ìš©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("MBTI ìœ í˜•ë³„ ë¹„ìœ¨ Top 10 êµ­ê°€ ğŸ“Š")
status = ""

p = Path(DEFAULT_FILE)
if p.exists():
    raw = pd.read_csv(p)
    df = normalize_to_long(raw)
    status = f"í´ë”ì˜ ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©: ./{DEFAULT_FILE}"
else:
    status = "í´ë”ì—ì„œ ê¸°ë³¸ CSVë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ì—…ë¡œë“œí•˜ì„¸ìš”."
    uploaded = st.file_uploader("CSV ì—…ë¡œë“œ (wide ë˜ëŠ” long í¬ë§·)", type=["csv"])
    if uploaded is None:
        st.info(status)
        st.stop()
    raw = pd.read_csv(uploaded)
    df = normalize_to_long(raw)
    status = "ì—…ë¡œë“œí•œ CSV ì‚¬ìš© ì¤‘"

st.caption(status)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° í’ˆì§ˆ ì ê²€(êµ­ê°€ë³„ í•©ê³„â‰ˆ100%)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.expander("ë°ì´í„° í’ˆì§ˆ ì ê²€ ë³´ê¸° (êµ­ê°€ë³„ í•©ê³„â‰ˆ100%)", expanded=False):
    sums = df.groupby("country")["percentage"].sum().round(2)
    offenders = sums[(sums < 99.5) | (sums > 100.5)].to_frame("sum_%")
    st.write(f"ì´ êµ­ê°€ ìˆ˜: **{df['country'].nunique()}**")
    st.write(f"ì˜¤ì°¨(Â±0.5%) ë²—ì–´ë‚œ êµ­ê°€ ìˆ˜: **{len(offenders)}**")
    if len(offenders):
        st.dataframe(offenders.sort_values("sum_%"))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UI ì»¨íŠ¸ë¡¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
colA, colB, colC = st.columns([2,1,1])
with colA:
    types_sorted = sorted(df["type"].unique())
    default_idx = types_sorted.index("ENFP") if "ENFP" in types_sorted else 0
    sel_type = st.selectbox("MBTI ìœ í˜• ì„ íƒ", types_sorted, index=default_idx)
with colB:
    top_n = st.number_input("Top N", min_value=3, max_value=20, value=10, step=1)
with colC:
    show_labels = st.checkbox("ë§‰ëŒ€ ë ˆì´ë¸” í‘œì‹œ", value=True)

# ì„ íƒ ìœ í˜• Top N
df_top = (
    df[df["type"] == sel_type]
    .dropna(subset=["percentage"])
    .nlargest(int(top_n), "percentage")
    .sort_values("percentage", ascending=True)
)

st.subheader(f"{sel_type} ë¹„ìœ¨ì´ ë†’ì€ êµ­ê°€ Top {int(top_n)}")
if df_top.empty:
    st.warning("í•´ë‹¹ ìœ í˜• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    base = alt.Chart(df_top).encode(
        y=alt.Y("country:N", sort=None, title="êµ­ê°€"),
        x=alt.X("percentage:Q", title="ë¹„ìœ¨(%)"),
        tooltip=[
            alt.Tooltip("country:N", title="êµ­ê°€"),
            alt.Tooltip("percentage:Q", title="ë¹„ìœ¨(%)", format=".2f")
        ]
    )
    bars = base.mark_bar().interactive()
    chart = bars
    if show_labels:
        text = base.mark_text(align="left", dx=3).encode(text=alt.Text("percentage:Q", format=".2f"))
        chart = bars + text
    st.altair_chart(chart.properties(height=max(320, 24*len(df_top)), width=720), use_container_width=True)

    with st.expander("í‘œë¡œ ë³´ê¸° / ë‹¤ìš´ë¡œë“œ"):
        st.dataframe(df_top[["country","type","percentage"]].sort_values("percentage", ascending=False), use_container_width=True)
        st.download_button(
            "ì´ í…Œì´ë¸” CSV ë‹¤ìš´ë¡œë“œ",
            data=df_top.to_csv(index=False).encode("utf-8"),
            file_name=f"top{int(top_n)}_{sel_type}.csv",
            mime="text/csv"
        )

# ì „ì²´ ìœ í˜•ë³„ Top N ë¯¸ë¦¬ë³´ê¸°(í…Œì´ë¸”)
with st.expander("ì „ì²´ ìœ í˜•ë³„ Top N ë¯¸ë¦¬ë³´ê¸°(í…Œì´ë¸”)"):
    top_all = (
        df.sort_values(["type","percentage"], ascending=[True, False])
        .groupby("type").head(int(top_n)).reset_index(drop=True)
    )
    st.dataframe(top_all, use_container_width=True)
